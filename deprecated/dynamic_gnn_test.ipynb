{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d42744-7d05-4350-8b7c-b0990a9974b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T19:44:21.284721Z",
     "iopub.status.busy": "2025-03-27T19:44:21.284476Z",
     "iopub.status.idle": "2025-03-27T19:44:21.309459Z",
     "shell.execute_reply": "2025-03-27T19:44:21.308542Z",
     "shell.execute_reply.started": "2025-03-27T19:44:21.284707Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_prep'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     38\u001b[39m     CDLIB_AVAILABLE = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Import utility functions from other notebooks\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# In a real scenario, these would be imported from a module\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_prep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (load_data, create_graph_from_edgelist, generate_synthetic_graph, plot_graph)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgnn_community_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (nx_to_pyg, extract_embeddings, detect_communities_from_embeddings,\n\u001b[32m     44\u001b[39m                                    evaluate_communities, plot_embeddings, add_communities_to_graph)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'data_prep'"
     ]
    }
   ],
   "source": [
    "# Dynamic Graph Neural Networks for Community Detection\n",
    "# ====================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For PyTorch and PyTorch Geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "try:\n",
    "    from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
    "    from torch_geometric.data import Data, Batch\n",
    "    from torch_geometric.utils import to_networkx, from_networkx\n",
    "    TORCH_GEOMETRIC_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TORCH_GEOMETRIC_AVAILABLE = False\n",
    "    print(\"PyTorch Geometric not available. Please install it for GNN-based methods.\")\n",
    "\n",
    "# For community evaluation\n",
    "try:\n",
    "    from cdlib import evaluation\n",
    "    CDLIB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CDLIB_AVAILABLE = False\n",
    "\n",
    "# Import utility functions from other notebooks\n",
    "# In a real scenario, these would be imported from a module\n",
    "from data_prep import (load_data, create_graph_from_edgelist, generate_synthetic_graph, plot_graph)\n",
    "from gnn_community_detection import (nx_to_pyg, extract_embeddings, detect_communities_from_embeddings,\n",
    "                                   evaluate_communities, plot_embeddings, add_communities_to_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741dc3fc-c37f-4380-8e19-96d9d8d9fbec",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-27T19:44:09.090934Z",
     "iopub.status.idle": "2025-03-27T19:44:09.091173Z",
     "shell.execute_reply": "2025-03-27T19:44:09.091077Z",
     "shell.execute_reply.started": "2025-03-27T19:44:09.091056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate a sequence of dynamic graphs\n",
    "def generate_dynamic_graphs(n_time_steps=5, n_nodes=100, n_communities=5, \n",
    "                            change_fraction=0.1, seed=42):\n",
    "    \"\"\"\n",
    "    Generate a sequence of dynamic graphs with evolving community structure\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_time_steps: int\n",
    "        Number of time steps\n",
    "    n_nodes: int\n",
    "        Number of nodes in each graph\n",
    "    n_communities: int\n",
    "        Number of communities\n",
    "    change_fraction: float\n",
    "        Fraction of nodes that change communities between time steps\n",
    "    seed: int\n",
    "        Random seed\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    graphs: list\n",
    "        List of NetworkX graphs for each time step\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Initialize graphs list\n",
    "    graphs = []\n",
    "    \n",
    "    # Generate initial graph\n",
    "    G_init, _ = generate_synthetic_graph('sbm', n_nodes=n_nodes, n_communities=n_communities,\n",
    "                                       p_in=0.3, p_out=0.05)\n",
    "    \n",
    "    # Get initial community assignments\n",
    "    community_assignments = np.array([G_init.nodes[i]['community'] for i in range(n_nodes)])\n",
    "    \n",
    "    # Add first graph to list\n",
    "    graphs.append(G_init)\n",
    "    \n",
    "    # Generate subsequent graphs with evolving community structure\n",
    "    for t in range(1, n_time_steps):\n",
    "        # Decide which nodes change communities\n",
    "        n_changes = int(n_nodes * change_fraction)\n",
    "        change_indices = np.random.choice(n_nodes, n_changes, replace=False)\n",
    "        \n",
    "        # Update community assignments\n",
    "        for idx in change_indices:\n",
    "            # Assign a different community\n",
    "            current_comm = community_assignments[idx]\n",
    "            available_comms = [c for c in range(n_communities) if c != current_comm]\n",
    "            new_comm = np.random.choice(available_comms)\n",
    "            community_assignments[idx] = new_comm\n",
    "        \n",
    "        # Create probability matrix for SBM based on updated communities\n",
    "        sizes = [np.sum(community_assignments == c) for c in range(n_communities)]\n",
    "        p_in = 0.3  # probability within community\n",
    "        p_out = 0.05  # probability between communities\n",
    "        \n",
    "        # Create probability matrix\n",
    "        p_matrix = np.ones((n_communities, n_communities)) * p_out\n",
    "        np.fill_diagonal(p_matrix, p_in)\n",
    "        \n",
    "        # Generate new graph\n",
    "        G_t = nx.stochastic_block_model(sizes, p_matrix, seed=seed+t)\n",
    "        \n",
    "        # Add community assignments as node attributes\n",
    "        node_index = 0\n",
    "        for comm, size in enumerate(sizes):\n",
    "            for _ in range(size):\n",
    "                G_t.nodes[node_index]['community'] = comm\n",
    "                node_index += 1\n",
    "        \n",
    "        # Add to graphs list\n",
    "        graphs.append(G_t)\n",
    "    \n",
    "    return graphs\n",
    "\n",
    "\n",
    "# Function to visualize dynamic communities\n",
    "def visualize_dynamic_communities(graphs, community_attr='community', figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Visualize the evolution of communities in dynamic graphs\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    graphs: list\n",
    "        List of NetworkX graphs for each time step\n",
    "    community_attr: str\n",
    "        Node attribute for community assignment\n",
    "    figsize: tuple\n",
    "        Figure size\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    n_time_steps = len(graphs)\n",
    "    \n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(1, n_time_steps, figsize=figsize)\n",
    "    if n_time_steps == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Visualize each time step\n",
    "    for t, G in enumerate(graphs):\n",
    "        # Get communities\n",
    "        communities = [G.nodes[i][community_attr] for i in range(len(G))]\n",
    "        \n",
    "        # Calculate layout (use same layout for all time steps)\n",
    "        if t == 0:\n",
    "            pos = nx.spring_layout(G, seed=42)\n",
    "        \n",
    "        # Plot\n",
    "        ax = axes[t]\n",
    "        nx.draw_networkx(G, pos=pos, node_color=communities, cmap='rainbow',\n",
    "                         with_labels=False, node_size=80, ax=ax)\n",
    "        ax.set_title(f'Time Step {t+1}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 1. EvolveGCN model\n",
    "class EvolveGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super(EvolveGCN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Initial weights for the GCN layers\n",
    "        self.weights = nn.ParameterList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.weights.append(nn.Parameter(torch.Tensor(input_dim, hidden_dim)))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.weights.append(nn.Parameter(torch.Tensor(hidden_dim, hidden_dim)))\n",
    "        \n",
    "        # Output layer\n",
    "        self.weights.append(nn.Parameter(torch.Tensor(hidden_dim, output_dim)))\n",
    "        \n",
    "        # RNN for weight evolution\n",
    "        self.weight_rnn = nn.GRUCell(hidden_dim * output_dim, hidden_dim * output_dim)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for weight in self.weights:\n",
    "            nn.init.xavier_uniform_(weight)\n",
    "    \n",
    "    def forward(self, x, edge_index, prev_weights=None):\n",
    "        # If no previous weights, use current weights\n",
    "        if prev_weights is None:\n",
    "            prev_weights = self.weights\n",
    "        \n",
    "        # Evolve weights if previous weights are provided\n",
    "        else:\n",
    "            # Evolve last layer weights (simplified for demonstration)\n",
    "            last_weight = prev_weights[-1]\n",
    "            flat_weight = last_weight.view(-1)\n",
    "            evolved_weight = self.weight_rnn(flat_weight, flat_weight)\n",
    "            self.weights[-1] = nn.Parameter(evolved_weight.view(self.hidden_dim, self.output_dim))\n",
    "        \n",
    "        # Apply GCN with evolved weights\n",
    "        for i, weight in enumerate(self.weights[:-1]):\n",
    "            x = F.relu(F.linear(x, weight))\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        # Output layer\n",
    "        x = F.linear(x, self.weights[-1])\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# 2. DySAT: Dynamic Self-Attention Network (simplified)\n",
    "class DySAT(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_heads=8, num_layers=2):\n",
    "        super(DySAT, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # Structural attention (simplified to GAT)\n",
    "        self.struct_attention = nn.ModuleList()\n",
    "        self.struct_attention.append(GATConv(input_dim, hidden_dim // num_heads, heads=num_heads))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.struct_attention.append(\n",
    "                GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads))\n",
    "        \n",
    "        self.struct_attention.append(\n",
    "            GATConv(hidden_dim, output_dim // num_heads, heads=num_heads, concat=True))\n",
    "        \n",
    "        # Temporal attention would go here in a full implementation\n",
    "        # Simplified for this example\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # Apply structural attention\n",
    "        for i, attention in enumerate(self.struct_attention[:-1]):\n",
    "            x = attention(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.struct_attention[-1](x, edge_index)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Function to train dynamic GNN model on a sequence of graphs\n",
    "def train_dynamic_gnn(model_type, graphs, embedding_dim=16, epochs=100, lr=0.01):\n",
    "    \"\"\"\n",
    "    Train a dynamic GNN model on a sequence of graphs\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_type: str\n",
    "        Type of dynamic GNN model ('evolvegcn' or 'dysat')\n",
    "    graphs: list\n",
    "        List of NetworkX graphs for each time step\n",
    "    embedding_dim: int\n",
    "        Dimension of node embeddings\n",
    "    epochs: int\n",
    "        Number of training epochs\n",
    "    lr: float\n",
    "        Learning rate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    model: torch.nn.Module\n",
    "        Trained dynamic GNN model\n",
    "    data_list: list\n",
    "        List of PyTorch Geometric Data objects for each time step\n",
    "    \"\"\"\n",
    "    if not TORCH_GEOMETRIC_AVAILABLE:\n",
    "        raise ImportError(\"PyTorch Geometric not available\")\n",
    "    \n",
    "    # Convert graphs to PyG Data objects\n",
    "    data_list = [nx_to_pyg(G) for G in graphs]\n",
    "    \n",
    "    # Get dimensions\n",
    "    input_dim = data_list[0].x.size(1)\n",
    "    \n",
    "    # Initialize model\n",
    "    if model_type.lower() == 'evolvegcn':\n",
    "        model = EvolveGCN(input_dim, hidden_dim=32, output_dim=embedding_dim)\n",
    "    elif model_type.lower() == 'dysat':\n",
    "        model = DySAT(input_dim, hidden_dim=32, output_dim=embedding_dim)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Process each time step\n",
    "        prev_weights = None\n",
    "        total_loss = 0\n",
    "        \n",
    "        for t, data in enumerate(data_list):\n",
    "            # Forward pass\n",
    "            if model_type.lower() == 'evolvegcn':\n",
    "                output = model(data.x, data.edge_index, prev_weights)\n",
    "                prev_weights = model.weights\n",
    "            else:\n",
    "                output = model(data.x, data.edge_index)\n",
    "            \n",
    "            # If we have ground truth communities, use supervised loss\n",
    "            if data.y is not None:\n",
    "                loss = F.cross_entropy(output, data.y)\n",
    "            else:\n",
    "                # For unsupervised setting, use a simplified loss\n",
    "                # In a real implementation, this would be more sophisticated\n",
    "                loss = torch.tensor(0.0, requires_grad=True)\n",
    "            \n",
    "            total_loss += loss\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss.item():.4f}')\n",
    "    \n",
    "    return model, data_list\n",
    "\n",
    "\n",
    "# Function to extract temporal embeddings from trained dynamic GNN\n",
    "def extract_temporal_embeddings(model, data_list, model_type='evolvegcn'):\n",
    "    \"\"\"\n",
    "    Extract node embeddings for each time step\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: torch.nn.Module\n",
    "        Trained dynamic GNN model\n",
    "    data_list: list\n",
    "        List of PyTorch Geometric Data objects for each time step\n",
    "    model_type: str\n",
    "        Type of dynamic GNN model ('evolvegcn' or 'dysat')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    embeddings_list: list\n",
    "        List of node embeddings for each time step\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings_list = []\n",
    "    prev_weights = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for t, data in enumerate(data_list):\n",
    "            # Forward pass\n",
    "            if model_type.lower() == 'evolvegcn':\n",
    "                embeddings = model(data.x, data.edge_index, prev_weights)\n",
    "                prev_weights = model.weights\n",
    "            else:\n",
    "                embeddings = model(data.x, data.edge_index)\n",
    "            \n",
    "            # Convert to numpy\n",
    "            embeddings_np = embeddings.detach().cpu().numpy()\n",
    "            embeddings_list.append(embeddings_np)\n",
    "    \n",
    "    return embeddings_list\n",
    "\n",
    "\n",
    "# Function to detect communities from temporal embeddings\n",
    "def detect_temporal_communities(embeddings_list, n_clusters=None, method='kmeans'):\n",
    "    \"\"\"\n",
    "    Detect communities from temporal embeddings\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    embeddings_list: list\n",
    "        List of node embeddings for each time step\n",
    "    n_clusters: int\n",
    "        Number of clusters (communities)\n",
    "    method: str\n",
    "        Clustering method ('kmeans' or 'spectral')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities_list: list\n",
    "        List of community assignments for each time step\n",
    "    \"\"\"\n",
    "    communities_list = []\n",
    "    \n",
    "    for t, embeddings in enumerate(embeddings_list):\n",
    "        # Detect communities for this time step\n",
    "        communities = detect_communities_from_embeddings(\n",
    "            embeddings, n_clusters=n_clusters, method=method)\n",
    "        \n",
    "        communities_list.append(communities)\n",
    "    \n",
    "    return communities_list\n",
    "\n",
    "\n",
    "# Function to evaluate temporal communities against ground truth\n",
    "def evaluate_temporal_communities(communities_list, graphs, ground_truth_attr='community'):\n",
    "    \"\"\"\n",
    "    Evaluate detected communities against ground truth for each time step\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    communities_list: list\n",
    "        List of community assignments for each time step\n",
    "    graphs: list\n",
    "        List of NetworkX graphs for each time step\n",
    "    ground_truth_attr: str\n",
    "        Node attribute for ground truth communities\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    metrics_list: list\n",
    "        List of evaluation metrics for each time step\n",
    "    \"\"\"\n",
    "    metrics_list = []\n",
    "    \n",
    "    for t, (communities, G) in enumerate(zip(communities_list, graphs)):\n",
    "        # Get ground truth\n",
    "        ground_truth = np.array([G.nodes[i][ground_truth_attr] for i in range(len(G))])\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_communities(communities, ground_truth)\n",
    "        metrics_list.append(metrics)\n",
    "    \n",
    "    return metrics_list\n",
    "\n",
    "\n",
    "# Function to visualize community evolution\n",
    "def visualize_community_evolution(communities_list, n_nodes, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Visualize the evolution of community assignments over time\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    communities_list: list\n",
    "        List of community assignments for each time step\n",
    "    n_nodes: int\n",
    "        Number of nodes\n",
    "    figsize: tuple\n",
    "        Figure size\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    n_time_steps = len(communities_list)\n",
    "    \n",
    "    # Prepare data for visualization\n",
    "    community_data = np.zeros((n_nodes, n_time_steps))\n",
    "    \n",
    "    for t, communities in enumerate(communities_list):\n",
    "        community_data[:, t] = communities\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(community_data, aspect='auto', cmap='rainbow')\n",
    "    plt.colorbar(label='Community')\n",
    "    plt.title('Community Evolution Over Time')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Node ID')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to run dynamic community detection\n",
    "def run_dynamic_community_detection(graphs, model_type='evolvegcn', embedding_dim=16, \n",
    "                                   n_clusters=None, epochs=100):\n",
    "    \"\"\"\n",
    "    Run dynamic community detection using a dynamic GNN model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    graphs: list\n",
    "        List of NetworkX graphs for each time step\n",
    "    model_type: str\n",
    "        Type of dynamic GNN model ('evolvegcn' or 'dysat')\n",
    "    embedding_dim: int\n",
    "        Dimension of node embeddings\n",
    "    n_clusters: int\n",
    "        Number of clusters (communities)\n",
    "    epochs: int\n",
    "        Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results: dict\n",
    "        Results including embeddings, communities, and evaluation metrics\n",
    "    \"\"\"\n",
    "    if not TORCH_GEOMETRIC_AVAILABLE:\n",
    "        raise ImportError(\"PyTorch Geometric not available\")\n",
    "    \n",
    "    # Train dynamic GNN model\n",
    "    print(f\"Training {model_type.upper()} model...\")\n",
    "    start_time = time.time()\n",
    "    model, data_list = train_dynamic_gnn(model_type, graphs, embedding_dim, epochs)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Extract temporal embeddings\n",
    "    print(\"Extracting temporal embeddings...\")\n",
    "    embeddings_list = extract_temporal_embeddings(model, data_list, model_type)\n",
    "    \n",
    "    # If n_clusters not specified, try to infer from ground truth\n",
    "    if n_clusters is None and 'community' in graphs[0].nodes[0]:\n",
    "        communities = [graphs[0].nodes[i]['community'] for i in range(len(graphs[0]))]\n",
    "        n_clusters = len(set(communities))\n",
    "    \n",
    "    # Detect communities\n",
    "    print(f\"Detecting communities with KMeans (n_clusters={n_clusters})...\")\n",
    "    communities_list = detect_temporal_communities(embeddings_list, n_clusters)\n",
    "    \n",
    "    # Visualize embeddings for each time step\n",
    "    print(\"Visualizing node embeddings for each time step...\")\n",
    "    for t, embeddings in enumerate(embeddings_list):\n",
    "        plot_embeddings(embeddings, communities_list[t], \n",
    "                       title=f\"Time Step {t+1} - Node Embeddings\")\n",
    "    \n",
    "    # Add communities to graphs\n",
    "    for t, (G, communities) in enumerate(zip(graphs, communities_list)):\n",
    "        add_communities_to_graph(G, communities)\n",
    "    \n",
    "    # Visualize detected communities\n",
    "    print(\"Visualizing detected communities...\")\n",
    "    visualize_dynamic_communities(graphs, community_attr='detected_community')\n",
    "    \n",
    "    # Visualize community evolution\n",
    "    print(\"Visualizing community evolution...\")\n",
    "    visualize_community_evolution(communities_list, len(graphs[0]))\n",
    "    \n",
    "    # Evaluate against ground truth if available\n",
    "    results = {\n",
    "        'model_type': model_type,\n",
    "        'embeddings_list': embeddings_list,\n",
    "        'communities_list': communities_list,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    if 'community' in graphs[0].nodes[0]:\n",
    "        metrics_list = evaluate_temporal_communities(communities_list, graphs)\n",
    "        results['metrics_list'] = metrics_list\n",
    "        \n",
    "        # Print average metrics\n",
    "        avg_nmi = np.mean([m['nmi'] for m in metrics_list])\n",
    "        avg_ari = np.mean([m['ari'] for m in metrics_list])\n",
    "        \n",
    "        print(\"\\nEvaluation against ground truth:\")\n",
    "        print(f\"Average NMI: {avg_nmi:.4f}\")\n",
    "        print(f\"Average ARI: {avg_ari:.4f}\")\n",
    "        \n",
    "        # Plot metrics over time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        time_steps = range(1, len(metrics_list) + 1)\n",
    "        plt.plot(time_steps, [m['nmi'] for m in metrics_list], 'o-', label='NMI')\n",
    "        plt.plot(time_steps, [m['ari'] for m in metrics_list], 's-', label='ARI')\n",
    "        plt.title('Community Detection Performance Over Time')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to compare dynamic GNN models\n",
    "def compare_dynamic_gnn_models(graphs, embedding_dim=16, n_clusters=None, epochs=100):\n",
    "    \"\"\"\n",
    "    Compare different dynamic GNN models for community detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    graphs: list\n",
    "        List of NetworkX graphs for each time step\n",
    "    embedding_dim: int\n",
    "        Dimension of node embeddings\n",
    "    n_clusters: int\n",
    "        Number of clusters (communities)\n",
    "    epochs: int\n",
    "        Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df: DataFrame\n",
    "        DataFrame with comparison results\n",
    "    \"\"\"\n",
    "    model_types = ['evolvegcn', 'dysat']\n",
    "    results_list = []\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Running {model_type.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            results = run_dynamic_community_detection(graphs, model_type=model_type,\n",
    "                                                    embedding_dim=embedding_dim,\n",
    "                                                    n_clusters=n_clusters, epochs=epochs)\n",
    "            \n",
    "            # Calculate average metrics if available\n",
    "            if 'metrics_list' in results:\n",
    "                avg_nmi = np.mean([m['nmi'] for m in results['metrics_list']])\n",
    "                avg_ari = np.mean([m['ari'] for m in results['metrics_list']])\n",
    "            else:\n",
    "                avg_nmi = np.nan\n",
    "                avg_ari = np.nan\n",
    "            \n",
    "            # Collect results\n",
    "            result_entry = {\n",
    "                'Model': model_type.upper(),\n",
    "                'Training Time (s)': results['training_time'],\n",
    "                'Avg NMI': avg_nmi,\n",
    "                'Avg ARI': avg_ari\n",
    "            }\n",
    "            \n",
    "            results_list.append(result_entry)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running {model_type}: {e}\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Visualize comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot metrics\n",
    "    if 'Avg NMI' in results_df.columns and not results_df['Avg NMI'].isna().all():\n",
    "        plt.subplot(1, 2, 1)\n",
    "        results_df.plot(x='Model', y=['Avg NMI', 'Avg ARI'], kind='bar', ax=plt.gca())\n",
    "        plt.title('Average Community Detection Quality')\n",
    "        plt.ylabel('Score')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot training time\n",
    "    plt.subplot(1, 2, 2)\n",
    "    results_df.plot(x='Model', y='Training Time (s)', kind='bar', ax=plt.gca(), color='green')\n",
    "    plt.title('Training Time')\n",
    "    plt.ylabel('Seconds')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Main execution example\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Dynamic Graph Neural Networks for Community Detection\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if not TORCH_GEOMETRIC_AVAILABLE:\n",
    "        print(\"Error: PyTorch Geometric not available. Please install it first.\")\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Generate a sequence of dynamic graphs\n",
    "    print(\"\\n1. Generating a sequence of dynamic graphs...\")\n",
    "    n_time_steps = 5\n",
    "    n_communities = 3\n",
    "    graphs = generate_dynamic_graphs(n_time_steps=n_time_steps, n_nodes=100, \n",
    "                                    n_communities=n_communities, change_fraction=0.1)\n",
    "    \n",
    "    # Visualize original graphs with ground truth communities\n",
    "    print(\"\\n2. Visualizing ground truth communities over time...\")\n",
    "    visualize_dynamic_communities(graphs, community_attr='community')\n",
    "    \n",
    "    # Run dynamic community detection with a specific model\n",
    "    print(\"\\n3. Running EvolveGCN-based dynamic community detection...\")\n",
    "    results_evolvegcn = run_dynamic_community_detection(graphs, model_type='evolvegcn',\n",
    "                                                      embedding_dim=16, n_clusters=n_communities,\n",
    "                                                      epochs=50)\n",
    "    \n",
    "    # Compare different dynamic GNN models\n",
    "    print(\"\\n4. Comparing different dynamic GNN models...\")\n",
    "    comparison_results = compare_dynamic_gnn_models(graphs, embedding_dim=16,\n",
    "                                                  n_clusters=n_communities, epochs=50)\n",
    "    \n",
    "    print(\"\\n5. Summary of results:\")\n",
    "    print(comparison_results)\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca41812-8820-4ddc-b0b1-a16ba47f21b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
