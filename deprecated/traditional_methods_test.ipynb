{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0c0f34-55d7-4af9-8117-55dc8a0c32fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T19:45:19.671692Z",
     "iopub.status.busy": "2025-03-27T19:45:19.671376Z",
     "iopub.status.idle": "2025-03-27T19:45:21.046859Z",
     "shell.execute_reply": "2025-03-27T19:45:21.045875Z",
     "shell.execute_reply.started": "2025-03-27T19:45:19.671658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'graph_tool', 'infomap'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw', 'pyclustering'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap'}\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_prep'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m     CDLIB_AVAILABLE = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Import utility functions from the data preparation notebook\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# In a real scenario, these would be imported from a module\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_prep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (load_data, create_graph_from_edgelist, create_graph_from_adjacency,\n\u001b[32m     31\u001b[39m                        generate_synthetic_graph, compute_graph_statistics, plot_graph)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'data_prep'"
     ]
    }
   ],
   "source": [
    "# Traditional Community Detection Methods\n",
    "# ======================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For community detection\n",
    "try:\n",
    "    import community as community_louvain  # python-louvain\n",
    "    LOUVAIN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LOUVAIN_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from cdlib import algorithms, evaluation\n",
    "    CDLIB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CDLIB_AVAILABLE = False\n",
    "\n",
    "# Import utility functions from the data preparation notebook\n",
    "# In a real scenario, these would be imported from a module\n",
    "from data_prep import (load_data, create_graph_from_edgelist, create_graph_from_adjacency,\n",
    "                       generate_synthetic_graph, compute_graph_statistics, plot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa240fb1-dce2-45f9-a548-c2ba69565471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_louvain(G):\n",
    "    \"\"\"\n",
    "    Run the Louvain community detection algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to analyze\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if LOUVAIN_AVAILABLE:\n",
    "        # Using python-louvain\n",
    "        communities = community_louvain.best_partition(G)\n",
    "    elif CDLIB_AVAILABLE:\n",
    "        # Using cdlib\n",
    "        result = algorithms.louvain(G)\n",
    "        communities = {}\n",
    "        for i, comm in enumerate(result.communities):\n",
    "            for node in comm:\n",
    "                communities[node] = i\n",
    "    else:\n",
    "        # Fallback to NetworkX\n",
    "        try:\n",
    "            from networkx.algorithms import community\n",
    "            communities = community.louvain_communities(G)\n",
    "            # Convert to dict format\n",
    "            comm_dict = {}\n",
    "            for i, comm in enumerate(communities):\n",
    "                for node in comm:\n",
    "                    comm_dict[node] = i\n",
    "            communities = comm_dict\n",
    "        except:\n",
    "            raise ImportError(\"No community detection library available. Please install python-louvain or cdlib.\")\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "\n",
    "def run_leiden(G):\n",
    "    \"\"\"\n",
    "    Run the Leiden community detection algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to analyze\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    if not CDLIB_AVAILABLE:\n",
    "        raise ImportError(\"cdlib is required for Leiden algorithm\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = algorithms.leiden(G)\n",
    "    \n",
    "    communities = {}\n",
    "    for i, comm in enumerate(result.communities):\n",
    "        for node in comm:\n",
    "            communities[node] = i\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "\n",
    "def run_infomap(G):\n",
    "    \"\"\"\n",
    "    Run the Infomap community detection algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to analyze\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    if not CDLIB_AVAILABLE:\n",
    "        raise ImportError(\"cdlib is required for Infomap algorithm\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = algorithms.infomap(G)\n",
    "    \n",
    "    communities = {}\n",
    "    for i, comm in enumerate(result.communities):\n",
    "        for node in comm:\n",
    "            communities[node] = i\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "\n",
    "def run_label_propagation(G):\n",
    "    \"\"\"\n",
    "    Run the Label Propagation community detection algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to analyze\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if CDLIB_AVAILABLE:\n",
    "        # Using cdlib\n",
    "        result = algorithms.label_propagation(G)\n",
    "        communities = {}\n",
    "        for i, comm in enumerate(result.communities):\n",
    "            for node in comm:\n",
    "                communities[node] = i\n",
    "    else:\n",
    "        # Using NetworkX\n",
    "        from networkx.algorithms import community\n",
    "        result = community.label_propagation_communities(G)\n",
    "        communities = {}\n",
    "        for i, comm in enumerate(result):\n",
    "            for node in comm:\n",
    "                communities[node] = i\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "\n",
    "def run_girvan_newman(G, k=None):\n",
    "    \"\"\"\n",
    "    Run the Girvan-Newman community detection algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to analyze\n",
    "    k: int\n",
    "        Number of communities to detect\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if CDLIB_AVAILABLE:\n",
    "        # Using cdlib\n",
    "        result = algorithms.girvan_newman(G, level=k)\n",
    "        communities = {}\n",
    "        for i, comm in enumerate(result.communities):\n",
    "            for node in comm:\n",
    "                communities[node] = i\n",
    "    else:\n",
    "        # Using NetworkX\n",
    "        from networkx.algorithms import community\n",
    "        comp = community.girvan_newman(G)\n",
    "        \n",
    "        # Limit to k iterations if specified\n",
    "        if k is not None:\n",
    "            for _ in range(k-1):\n",
    "                next(comp)\n",
    "            communities_list = next(comp)\n",
    "        else:\n",
    "            # Default: get the first partition\n",
    "            communities_list = next(comp)\n",
    "        \n",
    "        communities = {}\n",
    "        for i, comm in enumerate(communities_list):\n",
    "            for node in comm:\n",
    "                communities[node] = i\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "\n",
    "def run_spectral_clustering(G, n_clusters):\n",
    "    \"\"\"\n",
    "    Run Spectral Clustering for community detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to analyze\n",
    "    n_clusters: int\n",
    "        Number of communities to detect\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get adjacency matrix\n",
    "    A = nx.to_numpy_array(G)\n",
    "    \n",
    "    # Run spectral clustering\n",
    "    spectral = SpectralClustering(n_clusters=n_clusters, \n",
    "                                  affinity='precomputed', \n",
    "                                  assign_labels='kmeans',\n",
    "                                  random_state=42)\n",
    "    labels = spectral.fit_predict(A)\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    communities = {node: labels[i] for i, node in enumerate(G.nodes())}\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "\n",
    "def run_walktrap(G):\n",
    "    \"\"\"\n",
    "    Run the Walktrap community detection algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to analyze\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    if not CDLIB_AVAILABLE:\n",
    "        raise ImportError(\"cdlib is required for Walktrap algorithm\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = algorithms.walktrap(G)\n",
    "    \n",
    "    communities = {}\n",
    "    for i, comm in enumerate(result.communities):\n",
    "        for node in comm:\n",
    "            communities[node] = i\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "\n",
    "def evaluate_against_ground_truth(G, detected_communities, ground_truth_attr='community'):\n",
    "    \"\"\"\n",
    "    Evaluate detected communities against ground truth\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph with community information\n",
    "    detected_communities: dict\n",
    "        Dictionary mapping node to detected community\n",
    "    ground_truth_attr: str\n",
    "        Node attribute name for ground truth community\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    metrics: dict\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Get ground truth communities\n",
    "    ground_truth = nx.get_node_attributes(G, ground_truth_attr)\n",
    "    \n",
    "    # Ensure both dictionaries have the same keys\n",
    "    nodes = list(G.nodes())\n",
    "    true_labels = [ground_truth.get(n, -1) for n in nodes]\n",
    "    pred_labels = [detected_communities.get(n, -1) for n in nodes]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    metrics['nmi'] = normalized_mutual_info_score(true_labels, pred_labels)\n",
    "    metrics['ari'] = adjusted_rand_score(true_labels, pred_labels)\n",
    "    \n",
    "    # Calculate modularity\n",
    "    if LOUVAIN_AVAILABLE:\n",
    "        metrics['modularity'] = community_louvain.modularity(detected_communities, G)\n",
    "    elif CDLIB_AVAILABLE:\n",
    "        # Convert to cdlib format\n",
    "        communities_list = []\n",
    "        for comm_id in set(detected_communities.values()):\n",
    "            comm = [n for n, c in detected_communities.items() if c == comm_id]\n",
    "            communities_list.append(comm)\n",
    "        \n",
    "        communities = evaluation.NodeClustering(communities_list, G)\n",
    "        metrics['modularity'] = evaluation.newman_girvan_modularity(communities).score\n",
    "    else:\n",
    "        metrics['modularity'] = \"Not available (install python-louvain or cdlib)\"\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def plot_communities(G, communities, pos=None, figsize=(12, 10), title=\"Community Detection Results\"):\n",
    "    \"\"\"\n",
    "    Visualize detected communities\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to visualize\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    pos: dict\n",
    "        Node positions for visualization\n",
    "    figsize: tuple\n",
    "        Figure size\n",
    "    title: str\n",
    "        Plot title\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if pos is None:\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "    \n",
    "    # Set node colors based on community\n",
    "    cmap = plt.cm.rainbow\n",
    "    node_colors = [communities[n] for n in G.nodes()]\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx(G, pos=pos, node_color=node_colors, cmap=cmap, \n",
    "                     with_labels=True, node_size=100, font_size=8, alpha=0.8)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_methods(G, ground_truth_attr='community', n_clusters=None):\n",
    "    \"\"\"\n",
    "    Compare different community detection methods\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph to analyze\n",
    "    ground_truth_attr: str\n",
    "        Node attribute name for ground truth community\n",
    "    n_clusters: int\n",
    "        Number of clusters for methods that require it\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results: DataFrame\n",
    "        DataFrame with comparison results\n",
    "    \"\"\"\n",
    "    methods = {\n",
    "        'Louvain': run_louvain,\n",
    "        'Label Propagation': run_label_propagation\n",
    "    }\n",
    "    \n",
    "    # Add methods that require cdlib\n",
    "    if CDLIB_AVAILABLE:\n",
    "        methods.update({\n",
    "            'Leiden': run_leiden,\n",
    "            'Infomap': run_infomap,\n",
    "            'Walktrap': run_walktrap\n",
    "        })\n",
    "    \n",
    "    # Add Girvan-Newman (can be slow for large graphs)\n",
    "    if G.number_of_nodes() < 1000:\n",
    "        methods['Girvan-Newman'] = lambda g: run_girvan_newman(g, k=n_clusters)\n",
    "    \n",
    "    # Add spectral clustering if n_clusters is provided\n",
    "    if n_clusters is not None:\n",
    "        methods['Spectral Clustering'] = lambda g: run_spectral_clustering(g, n_clusters)\n",
    "    \n",
    "    # Run all methods and collect results\n",
    "    results = []\n",
    "    \n",
    "    for method_name, method_func in methods.items():\n",
    "        print(f\"Running {method_name}...\")\n",
    "        try:\n",
    "            communities, execution_time = method_func(G)\n",
    "            \n",
    "            # Count number of detected communities\n",
    "            n_communities = len(set(communities.values()))\n",
    "            \n",
    "            # Evaluate against ground truth\n",
    "            metrics = evaluate_against_ground_truth(G, communities, ground_truth_attr)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Method': method_name,\n",
    "                'Num Communities': n_communities,\n",
    "                'NMI': metrics['nmi'],\n",
    "                'ARI': metrics['ari'],\n",
    "                'Modularity': metrics['modularity'] if isinstance(metrics['modularity'], float) else None,\n",
    "                'Execution Time (s)': execution_time\n",
    "            })\n",
    "            \n",
    "            # Visualize communities\n",
    "            plot_communities(G, communities, title=f\"{method_name} - {n_communities} communities\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running {method_name}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def save_communities(G, communities, output_path, save_graph=False):\n",
    "    \"\"\"\n",
    "    Save detected communities to file\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: NetworkX Graph\n",
    "        The graph analyzed\n",
    "    communities: dict\n",
    "        Dictionary mapping node to community\n",
    "    output_path: str\n",
    "        Path to save the results\n",
    "    save_graph: bool\n",
    "        Whether to also save the graph\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Save communities\n",
    "    df = pd.DataFrame({\n",
    "        'node': list(communities.keys()),\n",
    "        'community': list(communities.values())\n",
    "    })\n",
    "    df.to_csv(f\"{output_path}_communities.csv\", index=False)\n",
    "    \n",
    "    # Save graph if requested\n",
    "    if save_graph:\n",
    "        # Add communities as node attributes\n",
    "        for node, comm in communities.items():\n",
    "            G.nodes[node]['detected_community'] = comm\n",
    "        \n",
    "        # Save as GraphML\n",
    "        nx.write_graphml(G, f\"{output_path}_graph.graphml\")\n",
    "\n",
    "\n",
    "# Main execution example\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Traditional Community Detection Methods\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Generate a synthetic graph with ground truth communities\n",
    "    print(\"\\n1. Generating a Stochastic Block Model graph...\")\n",
    "    n_communities = 5\n",
    "    G, ground_truth = generate_synthetic_graph('sbm', n_nodes=100, n_communities=n_communities,\n",
    "                                              p_in=0.3, p_out=0.05)\n",
    "    \n",
    "    # Visualize original graph with ground truth\n",
    "    print(\"\\n2. Visualizing ground truth communities...\")\n",
    "    plot_graph(G, community_attr='community', title=\"Ground Truth Communities\")\n",
    "    \n",
    "    # Compare different community detection methods\n",
    "    print(\"\\n3. Comparing different community detection methods...\")\n",
    "    results = compare_methods(G, ground_truth_attr='community', n_clusters=n_communities)\n",
    "    \n",
    "    # Display comparison results\n",
    "    print(\"\\n4. Summary of results:\")\n",
    "    print(results)\n",
    "    \n",
    "    # Visualize comparison results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot NMI and ARI\n",
    "    plt.subplot(1, 2, 1)\n",
    "    results.plot(x='Method', y=['NMI', 'ARI'], kind='bar', ax=plt.gca())\n",
    "    plt.title('Quality Metrics by Method')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Plot execution time\n",
    "    plt.subplot(1, 2, 2)\n",
    "    results.plot(x='Method', y='Execution Time (s)', kind='bar', ax=plt.gca(), color='green')\n",
    "    plt.title('Execution Time by Method')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Run on a real-world network if available\n",
    "    try:\n",
    "        # Replace with your actual data loading code\n",
    "        # G_real = load_data(\"path/to/your/network/data\")\n",
    "        # compare_methods(G_real)\n",
    "        pass\n",
    "    except:\n",
    "        print(\"\\nNo real-world network data available.\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
