{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping Community Detection Methods\n",
    "\n",
    "This notebook explores methods for detecting overlapping communities, where nodes can belong to multiple communities simultaneously. We'll cover:\n",
    "\n",
    "1. Generating synthetic graphs with overlapping communities\n",
    "2. Implementing and applying overlapping community detection algorithms\n",
    "3. Evaluating detection results with metrics for overlapping communities\n",
    "4. Visualizing overlapping community structures\n",
    "5. Comparing different detection methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport numpy as np\nimport torch\nimport polars as pl\nimport rustworkx as rx\nimport networkx as nx  # Still needed for some algorithms and visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import visualization functions\nfrom community_detection.visualization import visualize_overlapping_communities\n\n# Import from evaluation module\nfrom community_detection.evaluation import save_result\n\n# Import overlapping community detection functions\nfrom community_detection.overlapping_community_detection import (\n    generate_synthetic_overlapping_graph, plot_overlapping_communities,\n    run_bigclam, run_demon, run_slpa, GNN_Overlapping, rwx_to_pyg_overlapping,\n    train_gnn_overlapping, predict_gnn_overlapping, run_gnn_overlapping,\n    evaluate_overlapping_communities\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check Required Libraries\n",
    "\n",
    "Let's check if the required libraries for overlapping community detection are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cdlib is available for traditional overlapping methods\n",
    "try:\n",
    "    from cdlib import algorithms, evaluation as cdlib_eval\n",
    "    from cdlib.classes import NodeClustering\n",
    "    CDLIB_AVAILABLE = True\n",
    "    print(\"cdlib is available.\")\n",
    "except ImportError:\n",
    "    CDLIB_AVAILABLE = False\n",
    "    print(\"cdlib is not available. Some methods will be skipped.\")\n",
    "    print(\"You can install it with: pip install cdlib\")\n",
    "\n",
    "# Check if PyTorch Geometric is available for GNN-based methods\n",
    "try:\n",
    "    import torch_geometric\n",
    "    from torch_geometric.data import Data\n",
    "    from torch_geometric.nn import GCNConv\n",
    "    TORCH_GEOMETRIC_AVAILABLE = True\n",
    "    print(\"PyTorch Geometric is available.\")\n",
    "except ImportError:\n",
    "    TORCH_GEOMETRIC_AVAILABLE = False\n",
    "    print(\"PyTorch Geometric is not available. GNN-based methods will be skipped.\")\n",
    "    print(\"You can install it with: pip install torch-geometric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Functions for Overlapping Community Detection\n",
    "\n",
    "Let's define the necessary functions for generating and analyzing overlapping communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_overlapping_graph(n_nodes: int = 100, \n",
    "                                       n_communities: int = 4,\n",
    "                                       overlap_size: int = 20,\n",
    "                                       p_in: float = 0.3,\n",
    "                                       p_out: float = 0.05,\n",
    "                                       seed: int = 42) -> tuple:\n",
    "    \"\"\"\n",
    "    Generate a synthetic graph with overlapping communities\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_nodes: int\n",
    "        Number of nodes\n",
    "    n_communities: int\n",
    "        Number of communities\n",
    "    overlap_size: int\n",
    "        Number of nodes that will belong to multiple communities\n",
    "    p_in: float\n",
    "        Probability of edge within a community\n",
    "    p_out: float\n",
    "        Probability of edge between communities\n",
    "    seed: int\n",
    "        Random seed\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    G: rustworkx.PyGraph\n",
    "        The generated graph\n",
    "    ground_truth: list\n",
    "        List of lists containing node indices for each community\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Calculate nodes per community\n",
    "    base_size = (n_nodes - overlap_size) // n_communities\n",
    "    remainder = (n_nodes - overlap_size) % n_communities\n",
    "    \n",
    "    # Assign nodes to communities\n",
    "    community_sizes = [base_size + (1 if i < remainder else 0) for i in range(n_communities)]\n",
    "    \n",
    "    # Assign non-overlapping nodes to communities\n",
    "    communities = [[] for _ in range(n_communities)]\n",
    "    node_id = 0\n",
    "    \n",
    "    for i, size in enumerate(community_sizes):\n",
    "        for _ in range(size):\n",
    "            communities[i].append(node_id)\n",
    "            node_id += 1\n",
    "    \n",
    "    # Distribute overlapping nodes\n",
    "    overlap_assignments = []\n",
    "    \n",
    "    # Each overlapping node belongs to 2 communities\n",
    "    for i in range(overlap_size):\n",
    "        # Randomly select 2 distinct communities\n",
    "        comm_indices = np.random.choice(n_communities, 2, replace=False)\n",
    "        overlap_assignments.append(list(comm_indices))\n",
    "        \n",
    "        # Add the overlapping node to both communities\n",
    "        for comm_idx in comm_indices:\n",
    "            communities[comm_idx].append(node_id)\n",
    "        \n",
    "        node_id += 1\n",
    "    \n",
    "    # Create the graph using rustworkx\n",
    "    G = rx.PyGraph()\n",
    "    \n",
    "    # Add all nodes\n",
    "    for i in range(n_nodes):\n",
    "        G.add_node(None)\n",
    "    \n",
    "    # Add edges based on communities\n",
    "    # Nodes in the same community have higher probability (p_in) of being connected\n",
    "    # Nodes in different communities have lower probability (p_out) of being connected\n",
    "    \n",
    "    # Create a matrix tracking which communities each node belongs to\n",
    "    node_memberships = [[] for _ in range(n_nodes)]\n",
    "    for comm_idx, comm_nodes in enumerate(communities):\n",
    "        for node in comm_nodes:\n",
    "            node_memberships[node].append(comm_idx)\n",
    "    \n",
    "    # Add edges based on community membership\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(i+1, n_nodes):\n",
    "            # Check if nodes share a community\n",
    "            shared_community = any(comm in node_memberships[j] for comm in node_memberships[i])\n",
    "            \n",
    "            # Set probability based on community membership\n",
    "            p = p_in if shared_community else p_out\n",
    "            \n",
    "            # Add edge with probability p\n",
    "            if np.random.random() < p:\n",
    "                G.add_edge(i, j, None)\n",
    "    \n",
    "    return G, communities\n",
    "\n",
    "def _rwx_to_nx(G: rx.PyGraph) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Convert a RustworkX graph to a NetworkX graph\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: rx.PyGraph\n",
    "        RustworkX graph\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    G_nx: nx.Graph\n",
    "        NetworkX graph\n",
    "    \"\"\"\n",
    "    G_nx = nx.Graph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for i in range(len(G)):\n",
    "        G_nx.add_node(i, **({} if G.get_node_data(i) is None else G.get_node_data(i)))\n",
    "    \n",
    "    # Add edges\n",
    "    for edge in G.edge_list():\n",
    "        source, target = edge[0], edge[1]\n",
    "        edge_data = G.get_edge_data(source, target)\n",
    "        G_nx.add_edge(source, target, **({} if edge_data is None else edge_data))\n",
    "    \n",
    "    return G_nx\n",
    "\n",
    "def run_bigclam(G: rx.PyGraph, k: int = 5, iterations: int = 50) -> tuple:\n",
    "    \"\"\"\n",
    "    Run BigCLAM algorithm for overlapping community detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: rx.PyGraph\n",
    "        Graph to analyze\n",
    "    k: int\n",
    "        Number of communities to detect\n",
    "    iterations: int\n",
    "        Number of iterations for the algorithm\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: list\n",
    "        List of lists containing node indices for each community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    if not CDLIB_AVAILABLE:\n",
    "        raise ImportError(\"cdlib is required for BigCLAM algorithm\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert to NetworkX for cdlib\n",
    "    G_nx = _rwx_to_nx(G)\n",
    "    \n",
    "    # Run BigCLAM using cdlib\n",
    "    result = algorithms.bigclam(G_nx, k=k, iterations=iterations)\n",
    "    \n",
    "    # Extract communities\n",
    "    communities = result.communities\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "def run_demon(G: rx.PyGraph, epsilon: float = 0.25, min_com_size: int = 3) -> tuple:\n",
    "    \"\"\"\n",
    "    Run DEMON algorithm for overlapping community detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: rx.PyGraph\n",
    "        Graph to analyze\n",
    "    epsilon: float\n",
    "        Merging threshold\n",
    "    min_com_size: int\n",
    "        Minimum community size\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: list\n",
    "        List of lists containing node indices for each community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    if not CDLIB_AVAILABLE:\n",
    "        raise ImportError(\"cdlib is required for DEMON algorithm\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert to NetworkX for cdlib\n",
    "    G_nx = _rwx_to_nx(G)\n",
    "    \n",
    "    # Run DEMON using cdlib\n",
    "    result = algorithms.demon(G_nx, epsilon=epsilon, min_comm_size=min_com_size)\n",
    "    \n",
    "    # Extract communities\n",
    "    communities = result.communities\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "def run_slpa(G: rx.PyGraph, t: int = 21, r: float = 0.1) -> tuple:\n",
    "    \"\"\"\n",
    "    Run SLPA algorithm for overlapping community detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: rx.PyGraph\n",
    "        Graph to analyze\n",
    "    t: int\n",
    "        Number of iterations\n",
    "    r: float\n",
    "        Threshold for community inclusion\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: list\n",
    "        List of lists containing node indices for each community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    \"\"\"\n",
    "    if not CDLIB_AVAILABLE:\n",
    "        raise ImportError(\"cdlib is required for SLPA algorithm\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert to NetworkX for cdlib\n",
    "    G_nx = _rwx_to_nx(G)\n",
    "    \n",
    "    # Run SLPA using cdlib\n",
    "    result = algorithms.slpa(G_nx, t=t, r=r)\n",
    "    \n",
    "    # Extract communities\n",
    "    communities = result.communities\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time\n",
    "\n",
    "def rwx_to_pyg_overlapping(G: rx.PyGraph, communities: list = None) -> Data:\n",
    "    \"\"\"\n",
    "    Convert a RustworkX graph to a PyTorch Geometric Data object\n",
    "    with overlapping community information\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: rx.PyGraph\n",
    "        Graph to convert\n",
    "    communities: list\n",
    "        List of lists containing node indices for each community\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data: torch_geometric.data.Data\n",
    "        PyTorch Geometric Data object\n",
    "    \"\"\"\n",
    "    if not TORCH_GEOMETRIC_AVAILABLE:\n",
    "        raise ImportError(\"PyTorch Geometric is required\")\n",
    "    \n",
    "    # Get edges\n",
    "    edge_list = []\n",
    "    for edge in G.edge_list():\n",
    "        edge_list.append((edge[0], edge[1]))\n",
    "    \n",
    "    # Convert to PyG format\n",
    "    if edge_list:\n",
    "        edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "        # For undirected graph in PyG, we need both directions\n",
    "        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "    else:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "    \n",
    "    # Create node features (use degree as feature if not provided)\n",
    "    degrees = torch.tensor([G.degree(i) for i in range(len(G))])\n",
    "    max_degree = degrees.max().item()\n",
    "    x = torch.zeros((len(G), max_degree + 1), dtype=torch.float)\n",
    "    for i, degree in enumerate(degrees):\n",
    "        x[i, degree] = 1.0\n",
    "    \n",
    "    # Create community membership matrix if communities provided\n",
    "    if communities is not None:\n",
    "        y = torch.zeros((len(G), len(communities)), dtype=torch.float)\n",
    "        for i, comm in enumerate(communities):\n",
    "            for node in comm:\n",
    "                y[node, i] = 1.0\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    # Create PyG data object\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    return data\n",
    "\n",
    "class GNN_Overlapping(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    GNN model for overlapping community detection\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN_Overlapping, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = torch.relu(self.conv2(x, edge_index))\n",
    "        x = torch.sigmoid(self.conv3(x, edge_index))  # Sigmoid for multi-label output\n",
    "        return x\n",
    "\n",
    "def train_gnn_overlapping(model, data, epochs=100, lr=0.01, weight_decay=5e-4):\n",
    "    \"\"\"\n",
    "    Train a GNN model for overlapping community detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: torch.nn.Module\n",
    "        GNN model to train\n",
    "    data: torch_geometric.data.Data\n",
    "        PyG data object with overlapping community labels\n",
    "    epochs: int\n",
    "        Number of training epochs\n",
    "    lr: float\n",
    "        Learning rate\n",
    "    weight_decay: float\n",
    "        Weight decay factor\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    model: torch.nn.Module\n",
    "        Trained model\n",
    "    losses: list\n",
    "        List of training losses\n",
    "    \"\"\"\n",
    "    if not TORCH_GEOMETRIC_AVAILABLE:\n",
    "        raise ImportError(\"PyTorch Geometric is required\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.BCELoss()  # Binary cross-entropy for multi-label classification\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model, losses\n",
    "\n",
    "def predict_gnn_overlapping(model, data, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict overlapping communities using a trained GNN model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: torch.nn.Module\n",
    "        Trained GNN model\n",
    "    data: torch_geometric.data.Data\n",
    "        PyG data object\n",
    "    threshold: float\n",
    "        Threshold for community membership\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: list\n",
    "        List of lists containing node indices for each community\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index).cpu()\n",
    "    \n",
    "    # Convert predictions to communities\n",
    "    predictions = (out > threshold).float().numpy()\n",
    "    n_communities = predictions.shape[1]\n",
    "    \n",
    "    # Extract communities\n",
    "    communities = []\n",
    "    for i in range(n_communities):\n",
    "        community = np.where(predictions[:, i] > 0)[0].tolist()\n",
    "        if community:  # Only add non-empty communities\n",
    "            communities.append(community)\n",
    "    \n",
    "    return communities\n",
    "\n",
    "def run_gnn_overlapping(G: rx.PyGraph, ground_truth: list, hidden_dim: int = 64,\n",
    "                      epochs: int = 100, threshold: float = 0.5) -> tuple:\n",
    "    \"\"\"\n",
    "    Run GNN-based overlapping community detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G: rx.PyGraph\n",
    "        Graph to analyze\n",
    "    ground_truth: list\n",
    "        List of lists containing node indices for each community\n",
    "    hidden_dim: int\n",
    "        Hidden dimension of the GNN model\n",
    "    epochs: int\n",
    "        Number of training epochs\n",
    "    threshold: float\n",
    "        Threshold for community membership\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    communities: list\n",
    "        List of lists containing node indices for each community\n",
    "    execution_time: float\n",
    "        Execution time in seconds\n",
    "    losses: list\n",
    "        List of training losses\n",
    "    \"\"\"\n",
    "    if not TORCH_GEOMETRIC_AVAILABLE:\n",
    "        raise ImportError(\"PyTorch Geometric is required for GNN-based methods\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert to PyG data\n",
    "    data = rwx_to_pyg_overlapping(G, ground_truth)\n",
    "    \n",
    "    # Create model\n",
    "    model = GNN_Overlapping(\n",
    "        input_dim=data.x.size(1),\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=data.y.size(1)\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model, losses = train_gnn_overlapping(model, data, epochs=epochs)\n",
    "    \n",
    "    # Predict communities\n",
    "    communities = predict_gnn_overlapping(model, data, threshold=threshold)\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    return communities, execution_time, losses\n",
    "\n",
    "def evaluate_overlapping_communities(detected: list, ground_truth: list) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate overlapping community detection results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    detected: list\n",
    "        List of lists containing node indices for each detected community\n",
    "    ground_truth: list\n",
    "        List of lists containing node indices for each ground truth community\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    metrics: dict\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    if not CDLIB_AVAILABLE:\n",
    "        raise ImportError(\"cdlib is required for evaluation\")\n",
    "    \n",
    "    # Create a dummy graph for cdlib evaluation\n",
    "    # Get all unique nodes\n",
    "    all_nodes = set()\n",
    "    for comm in ground_truth + detected:\n",
    "        all_nodes.update(comm)\n",
    "    \n",
    "    G_dummy = nx.Graph()\n",
    "    G_dummy.add_nodes_from(all_nodes)\n",
    "    \n",
    "    # Convert to cdlib format\n",
    "    ground_truth_clustering = NodeClustering(ground_truth, G_dummy)\n",
    "    detected_clustering = NodeClustering(detected, G_dummy)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    \n",
    "    # Normalized Mutual Information\n",
    "    metrics['nmi'] = cdlib_eval.normalized_mutual_information(ground_truth_clustering, detected_clustering).score\n",
    "    \n",
    "    # Omega Index\n",
    "    metrics['omega'] = cdlib_eval.omega(ground_truth_clustering, detected_clustering).score\n",
    "    \n",
    "    # F1 Score (based on overlap)\n",
    "    # Compute precision and recall for each detected community against best matching ground truth community\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    \n",
    "    # For each detected community\n",
    "    for det_comm in detected:\n",
    "        det_comm_set = set(det_comm)\n",
    "        best_f1 = 0\n",
    "        best_precision = 0\n",
    "        best_recall = 0\n",
    "        \n",
    "        # Find best matching ground truth community\n",
    "        for gt_comm in ground_truth:\n",
    "            gt_comm_set = set(gt_comm)\n",
    "            \n",
    "            # Calculate overlap\n",
    "            intersection = len(det_comm_set & gt_comm_set)\n",
    "            \n",
    "            if intersection > 0:\n",
    "                precision = intersection / len(det_comm_set)  # TP / (TP + FP)\n",
    "                recall = intersection / len(gt_comm_set)      # TP / (TP + FN)\n",
    "                f1 = 2 * precision * recall / (precision + recall)\n",
    "                \n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_precision = precision\n",
    "                    best_recall = recall\n",
    "        \n",
    "        total_precision += best_precision\n",
    "        total_recall += best_recall\n",
    "    \n",
    "    # Calculate average precision and recall\n",
    "    avg_precision = total_precision / len(detected) if detected else 0\n",
    "    avg_recall = total_recall / len(detected) if detected else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if avg_precision + avg_recall > 0:\n",
    "        metrics['f1'] = 2 * avg_precision * avg_recall / (avg_precision + avg_recall)\n",
    "    else:\n",
    "        metrics['f1'] = 0\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate a Synthetic Graph with Overlapping Communities\n",
    "\n",
    "Let's create a synthetic graph with overlapping communities for our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic graph with overlapping communities\n",
    "print(\"Generating a synthetic graph with overlapping communities...\")\n",
    "n_communities = 4\n",
    "n_nodes = 100\n",
    "overlap_size = 20  # Number of nodes that will belong to multiple communities\n",
    "\n",
    "G, ground_truth = generate_synthetic_overlapping_graph(\n",
    "    n_nodes=n_nodes,\n",
    "    n_communities=n_communities,\n",
    "    overlap_size=overlap_size,\n",
    "    p_in=0.3,  # probability of edge within community\n",
    "    p_out=0.05  # probability of edge between communities\n",
    ")\n",
    "\n",
    "print(f\"Generated graph with {len(G)} nodes and {G.num_edges()} edges.\")\n",
    "print(f\"Created {n_communities} overlapping communities.\")\n",
    "\n",
    "# Visualize the ground truth overlapping communities\n",
    "print(\"\\nVisualizing ground truth overlapping communities...\")\n",
    "visualize_overlapping_communities(G, ground_truth, figsize=(12, 10), alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Overlapping Community Structure\n",
    "\n",
    "Let's analyze the structure of our overlapping communities to better understand them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ground truth overlapping communities\n",
    "print(\"Analyzing ground truth overlapping communities:\")\n",
    "\n",
    "# Count community sizes\n",
    "community_sizes = [len(comm) for comm in ground_truth]\n",
    "print(f\"Community sizes: {community_sizes}\")\n",
    "\n",
    "# Count number of communities per node\n",
    "node_memberships = {}\n",
    "for i, comm in enumerate(ground_truth):\n",
    "    for node in comm:\n",
    "        if node not in node_memberships:\n",
    "            node_memberships[node] = []\n",
    "        node_memberships[node].append(i)\n",
    "\n",
    "membership_counts = {node: len(comms) for node, comms in node_memberships.items()}\n",
    "membership_distribution = {}\n",
    "for count in membership_counts.values():\n",
    "    if count not in membership_distribution:\n",
    "        membership_distribution[count] = 0\n",
    "    membership_distribution[count] += 1\n",
    "\n",
    "print(\"\\nMembership distribution (number of nodes with N community memberships):\")\n",
    "for count, num_nodes in sorted(membership_distribution.items()):\n",
    "    print(f\"  {num_nodes} nodes belong to {count} communities\")\n",
    "\n",
    "# Plot the distribution of community memberships\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(membership_distribution.keys(), membership_distribution.values())\n",
    "plt.title('Distribution of Community Memberships')\n",
    "plt.xlabel('Number of Communities a Node Belongs To')\n",
    "plt.ylabel('Number of Nodes')\n",
    "plt.xticks(range(1, max(membership_distribution.keys()) + 1))\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Analyze overlap between communities\n",
    "print(\"\\nOverlap between communities:\")\n",
    "overlap_matrix = np.zeros((n_communities, n_communities))\n",
    "for i in range(n_communities):\n",
    "    for j in range(i+1, n_communities):\n",
    "        overlap = len(set(ground_truth[i]) & set(ground_truth[j]))\n",
    "        overlap_matrix[i, j] = overlap\n",
    "        overlap_matrix[j, i] = overlap\n",
    "        print(f\"  Communities {i} and {j} share {overlap} nodes\")\n",
    "\n",
    "# Visualize the overlap matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(overlap_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "plt.title('Overlap Between Communities')\n",
    "plt.xlabel('Community ID')\n",
    "plt.ylabel('Community ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BigCLAM Algorithm\n",
    "\n",
    "BigCLAM (Cluster Affiliation Model for Big Networks) is designed to detect overlapping communities in large networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CDLIB_AVAILABLE:\n",
    "    # Run BigCLAM algorithm\n",
    "    print(\"Running BigCLAM algorithm...\")\n",
    "    \n",
    "    # Set the number of communities to detect\n",
    "    k = len(ground_truth)\n",
    "    \n",
    "    # Run BigCLAM\n",
    "    bigclam_communities, bigclam_time = run_bigclam(G, k=k)\n",
    "    \n",
    "    # Evaluate against ground truth\n",
    "    bigclam_metrics = evaluate_overlapping_communities(bigclam_communities, ground_truth)\n",
    "    print(f\"Execution time: {bigclam_time:.4f} seconds\")\n",
    "    print(f\"Number of communities detected: {len(bigclam_communities)}\")\n",
    "    print(f\"NMI: {bigclam_metrics['nmi']:.4f}\")\n",
    "    print(f\"Omega Index: {bigclam_metrics['omega']:.4f}\")\n",
    "    print(f\"F1 Score: {bigclam_metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    bigclam_result = {\n",
    "        'communities': bigclam_communities,\n",
    "        'execution_time': bigclam_time,\n",
    "        'metrics': bigclam_metrics,\n",
    "        'num_communities': len(bigclam_communities)\n",
    "    }\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    with open('results/bigclam_result.pkl', 'wb') as f:\n",
    "        pickle.dump(bigclam_result, f)\n",
    "    \n",
    "    # Visualize detected communities\n",
    "    print(\"\\nVisualizing BigCLAM detected communities...\")\n",
    "    visualize_overlapping_communities(G, bigclam_communities, figsize=(12, 10), alpha=0.6)\n",
    "else:\n",
    "    print(\"BigCLAM requires cdlib. Skipping this method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DEMON Algorithm\n",
    "\n",
    "DEMON (Democratic Estimate of the Modular Organization of a Network) leverages local community information to identify overlapping communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CDLIB_AVAILABLE:\n",
    "    # Run DEMON algorithm\n",
    "    print(\"Running DEMON algorithm...\")\n",
    "    \n",
    "    # Run DEMON\n",
    "    demon_communities, demon_time = run_demon(G, epsilon=0.25)\n",
    "    \n",
    "    # Evaluate against ground truth\n",
    "    demon_metrics = evaluate_overlapping_communities(demon_communities, ground_truth)\n",
    "    print(f\"Execution time: {demon_time:.4f} seconds\")\n",
    "    print(f\"Number of communities detected: {len(demon_communities)}\")\n",
    "    print(f\"NMI: {demon_metrics['nmi']:.4f}\")\n",
    "    print(f\"Omega Index: {demon_metrics['omega']:.4f}\")\n",
    "    print(f\"F1 Score: {demon_metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    demon_result = {\n",
    "        'communities': demon_communities,\n",
    "        'execution_time': demon_time,\n",
    "        'metrics': demon_metrics,\n",
    "        'num_communities': len(demon_communities)\n",
    "    }\n",
    "    with open('results/demon_result.pkl', 'wb') as f:\n",
    "        pickle.dump(demon_result, f)\n",
    "    \n",
    "    # Visualize detected communities\n",
    "    print(\"\\nVisualizing DEMON detected communities...\")\n",
    "    visualize_overlapping_communities(G, demon_communities, figsize=(12, 10), alpha=0.6)\n",
    "else:\n",
    "    print(\"DEMON requires cdlib. Skipping this method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SLPA Algorithm\n",
    "\n",
    "Speaker-Listener Label Propagation Algorithm (SLPA) is an extension of Label Propagation that can detect overlapping communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CDLIB_AVAILABLE:\n",
    "    # Run SLPA algorithm\n",
    "    print(\"Running SLPA algorithm...\")\n",
    "    \n",
    "    # Run SLPA\n",
    "    slpa_communities, slpa_time = run_slpa(G, t=21, r=0.1)\n",
    "    \n",
    "    # Evaluate against ground truth\n",
    "    slpa_metrics = evaluate_overlapping_communities(slpa_communities, ground_truth)\n",
    "    print(f\"Execution time: {slpa_time:.4f} seconds\")\n",
    "    print(f\"Number of communities detected: {len(slpa_communities)}\")\n",
    "    print(f\"NMI: {slpa_metrics['nmi']:.4f}\")\n",
    "    print(f\"Omega Index: {slpa_metrics['omega']:.4f}\")\n",
    "    print(f\"F1 Score: {slpa_metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    slpa_result = {\n",
    "        'communities': slpa_communities,\n",
    "        'execution_time': slpa_time,\n",
    "        'metrics': slpa_metrics,\n",
    "        'num_communities': len(slpa_communities)\n",
    "    }\n",
    "    with open('results/slpa_result.pkl', 'wb') as f:\n",
    "        pickle.dump(slpa_result, f)\n",
    "    \n",
    "    # Visualize detected communities\n",
    "    print(\"\\nVisualizing SLPA detected communities...\")\n",
    "    visualize_overlapping_communities(G, slpa_communities, figsize=(12, 10), alpha=0.6)\n",
    "else:\n",
    "    print(\"SLPA requires cdlib. Skipping this method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. GNN-Based Overlapping Community Detection\n",
    "\n",
    "Let's implement a GNN-based approach for detecting overlapping communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_GEOMETRIC_AVAILABLE:\n",
    "    # Run GNN-based overlapping community detection\n",
    "    print(\"Running GNN-based overlapping community detection...\")\n",
    "    \n",
    "    # Run the GNN model\n",
    "    gnn_communities, gnn_time, gnn_losses = run_gnn_overlapping(\n",
    "        G, \n",
    "        ground_truth,  # In a real scenario, you would split the data and use cross-validation\n",
    "        hidden_dim=64,\n",
    "        epochs=100,\n",
    "        threshold=0.5\n",
    "    )\n",
    "    \n",
    "    # Evaluate against ground truth\n",
    "    gnn_metrics = evaluate_overlapping_communities(gnn_communities, ground_truth)\n",
    "    print(f\"Execution time: {gnn_time:.4f} seconds\")\n",
    "    print(f\"Number of communities detected: {len(gnn_communities)}\")\n",
    "    print(f\"NMI: {gnn_metrics['nmi']:.4f}\")\n",
    "    print(f\"Omega Index: {gnn_metrics['omega']:.4f}\")\n",
    "    print(f\"F1 Score: {gnn_metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    gnn_result = {\n",
    "        'communities': gnn_communities,\n",
    "        'execution_time': gnn_time,\n",
    "        'metrics': gnn_metrics,\n",
    "        'num_communities': len(gnn_communities),\n",
    "        'losses': gnn_losses\n",
    "    }\n",
    "    with open('results/gnn_overlapping_result.pkl', 'wb') as f:\n",
    "        pickle.dump(gnn_result, f)\n",
    "    \n",
    "    # Visualize detected communities\n",
    "    print(\"\\nVisualizing GNN detected communities...\")\n",
    "    visualize_overlapping_communities(G, gnn_communities, figsize=(12, 10), alpha=0.6)\n",
    "    \n",
    "    # Plot the training loss curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(gnn_losses)\n",
    "    plt.title('GNN Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"GNN-based methods require PyTorch Geometric. Skipping this method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparing Overlapping Community Detection Methods\n",
    "\n",
    "Now, let's run a comprehensive comparison of all the overlapping community detection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have at least one method available\n",
    "if CDLIB_AVAILABLE or TORCH_GEOMETRIC_AVAILABLE:\n",
    "    # Set up the results for comparison\n",
    "    results = []\n",
    "    \n",
    "    if CDLIB_AVAILABLE:\n",
    "        # Add BigCLAM results\n",
    "        if 'bigclam_metrics' in locals():\n",
    "            results.append({\n",
    "                'Method': 'BigCLAM',\n",
    "                'Num Communities': len(bigclam_communities),\n",
    "                'Avg Community Size': np.mean([len(comm) for comm in bigclam_communities]),\n",
    "                'NMI': bigclam_metrics['nmi'],\n",
    "                'Omega': bigclam_metrics['omega'],\n",
    "                'F1': bigclam_metrics['f1'],\n",
    "                'Execution Time (s)': bigclam_time\n",
    "            })\n",
    "        \n",
    "        # Add DEMON results\n",
    "        if 'demon_metrics' in locals():\n",
    "            results.append({\n",
    "                'Method': 'DEMON',\n",
    "                'Num Communities': len(demon_communities),\n",
    "                'Avg Community Size': np.mean([len(comm) for comm in demon_communities]),\n",
    "                'NMI': demon_metrics['nmi'],\n",
    "                'Omega': demon_metrics['omega'],\n",
    "                'F1': demon_metrics['f1'],\n",
    "                'Execution Time (s)': demon_time\n",
    "            })\n",
    "        \n",
    "        # Add SLPA results\n",
    "        if 'slpa_metrics' in locals():\n",
    "            results.append({\n",
    "                'Method': 'SLPA',\n",
    "                'Num Communities': len(slpa_communities),\n",
    "                'Avg Community Size': np.mean([len(comm) for comm in slpa_communities]),\n",
    "                'NMI': slpa_metrics['nmi'],\n",
    "                'Omega': slpa_metrics['omega'],\n",
    "                'F1': slpa_metrics['f1'],\n",
    "                'Execution Time (s)': slpa_time\n",
    "            })\n",
    "    \n",
    "    if TORCH_GEOMETRIC_AVAILABLE:\n",
    "        # Add GNN results\n",
    "        if 'gnn_metrics' in locals():\n",
    "            results.append({\n",
    "                'Method': 'GNN',\n",
    "                'Num Communities': len(gnn_communities),\n",
    "                'Avg Community Size': np.mean([len(comm) for comm in gnn_communities]),\n",
    "                'NMI': gnn_metrics['nmi'],\n",
    "                'Omega': gnn_metrics['omega'],\n",
    "                'F1': gnn_metrics['f1'],\n",
    "                'Execution Time (s)': gnn_time\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    if results:\n",
    "        # Use polars for DataFrame\n",
    "        comparison_df = pl.DataFrame(results)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nComparison Results:\")\n",
    "        print(comparison_df)\n",
    "        \n",
    "        # Save the comparison results\n",
    "        comparison_df.write_parquet('results/overlapping_methods_comparison.parquet', compression=\"zstd\")\n",
    "        \n",
    "        # Convert to pandas for visualization\n",
    "        comparison_pd = comparison_df.to_pandas()\n",
    "        \n",
    "        # Create visualizations\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Plot metrics\n",
    "        plt.subplot(2, 2, 1)\n",
    "        comparison_pd.plot(x='Method', y=['NMI', 'Omega', 'F1'], kind='bar', ax=plt.gca())\n",
    "        plt.title('Quality Metrics by Method')\n",
    "        plt.ylabel('Score')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Plot execution time\n",
    "        plt.subplot(2, 2, 2)\n",
    "        comparison_pd.plot(x='Method', y='Execution Time (s)', kind='bar', ax=plt.gca(), color='green')\n",
    "        plt.title('Execution Time by Method')\n",
    "        plt.ylabel('Time (seconds)')\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Plot number of communities\n",
    "        plt.subplot(2, 2, 3)\n",
    "        comparison_pd.plot(x='Method', y='Num Communities', kind='bar', ax=plt.gca(), color='orange')\n",
    "        plt.title('Number of Communities Detected')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Plot average community size\n",
    "        plt.subplot(2, 2, 4)\n",
    "        comparison_pd.plot(x='Method', y='Avg Community Size', kind='bar', ax=plt.gca(), color='purple')\n",
    "        plt.title('Average Community Size')\n",
    "        plt.ylabel('Size')\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/overlapping_methods_comparison.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No results available for comparison.\")\n",
    "else:\n",
    "    print(\"No methods were run. Please install cdlib or PyTorch Geometric to run the methods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Generated a synthetic graph with overlapping communities\n",
    "2. Applied various overlapping community detection methods\n",
    "   - BigCLAM (if cdlib was available)\n",
    "   - DEMON (if cdlib was available)\n",
    "   - SLPA (if cdlib was available)\n",
    "   - GNN-based approach (if PyTorch Geometric was available)\n",
    "3. Evaluated the methods using metrics designed for overlapping communities\n",
    "   - NMI (Normalized Mutual Information)\n",
    "   - Omega Index\n",
    "   - F1 Score\n",
    "4. Visualized the detected overlapping communities\n",
    "5. Compared the methods in terms of quality and performance\n",
    "\n",
    "Overlapping community detection is important for many real-world networks where nodes can naturally belong to multiple communities simultaneously, such as in social networks where people can be part of multiple social circles. The methods we've explored provide different approaches to identifying these complex community structures.\n",
    "\n",
    "In the next notebook, we'll perform a comprehensive evaluation of all the community detection methods we've explored in this series, comparing their performance across different types of graphs and community structures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}