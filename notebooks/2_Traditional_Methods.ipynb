{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Community Detection Methods\n",
    "\n",
    "This notebook demonstrates traditional community detection methods and evaluates their performance against ground truth communities. We'll cover:\n",
    "\n",
    "1. Loading previously created graphs\n",
    "2. Applying various traditional community detection algorithms\n",
    "3. Evaluating detection results\n",
    "4. Comparing different methods\n",
    "5. Visualizing detected communities"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T18:42:20.959547Z",
     "iopub.status.busy": "2025-03-31T18:42:20.956805Z",
     "iopub.status.idle": "2025-03-31T18:42:21.106180Z",
     "shell.execute_reply": "2025-03-31T18:42:21.105365Z",
     "shell.execute_reply.started": "2025-03-31T18:42:20.959459Z"
    }
   },
   "outputs": [],
   "source": "import sys\nimport os\nimport numpy as np\nimport torch\nimport polars as pl\nimport rustworkx as rx\nimport networkx as nx  # Still needed for some visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import directly from community_detection package\nfrom community_detection.traditional_methods import (\n    run_louvain, run_leiden, run_infomap, run_label_propagation,\n    run_spectral_clustering, run_girvan_newman, evaluate_against_ground_truth,\n    plot_communities, add_communities_to_graph, compare_methods, save_communities\n)\n\n# Import functions from data_prep for graph generation if needed\nfrom community_detection.data_prep import generate_synthetic_graph"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load or Generate Test Graphs\n",
    "\n",
    "First, let's load the synthetic graphs we created in the previous notebook, or generate a new one if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for data if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Check if previously saved graphs are available\n",
    "if os.path.exists('data/sbm_graph.gpickle'):\n",
    "    # Load the SBM graph using pickle format\n",
    "    print(\"Loading SBM graph from file...\")\n",
    "    with open('data/sbm_graph.gpickle', 'rb') as f:\n",
    "        G = pickle.load(f)\n",
    "else:\n",
    "    # Generate a new SBM graph\n",
    "    print(\"Generating a new SBM graph...\")\n",
    "    n_communities = 5\n",
    "    G, _ = generate_synthetic_graph(\n",
    "        'sbm', \n",
    "        n_nodes=100, \n",
    "        n_communities=n_communities,\n",
    "        p_in=0.3, \n",
    "        p_out=0.05\n",
    "    )\n",
    "    \n",
    "    # Save the graph in pickle format for future use\n",
    "    with open('data/sbm_graph.gpickle', 'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "    print(\"Generated and saved new SBM graph.\")\n",
    "\n",
    "# Extract ground truth communities\n",
    "ground_truth = {}\n",
    "for i in range(len(G)):\n",
    "    node_data = G.get_node_data(i)\n",
    "    if node_data and 'community' in node_data:\n",
    "        ground_truth[i] = node_data['community']\n",
    "\n",
    "# Visualize the graph with ground truth communities\n",
    "plot_communities(G, ground_truth, title=\"Ground Truth Communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply Individual Community Detection Methods\n",
    "\n",
    "Let's apply various traditional community detection methods one by one and evaluate their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Louvain Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Louvain algorithm\n",
    "print(\"Running Louvain method...\")\n",
    "louvain_communities, louvain_time = run_louvain(G)\n",
    "\n",
    "# Add detected communities to the graph\n",
    "G = add_communities_to_graph(G, louvain_communities, attr_name='louvain_community')\n",
    "\n",
    "# Evaluate against ground truth\n",
    "louvain_metrics = evaluate_against_ground_truth(G, louvain_communities, 'community')\n",
    "print(f\"Execution time: {louvain_time:.4f} seconds\")\n",
    "print(f\"Number of communities detected: {len(set(louvain_communities.values()))}\")\n",
    "print(f\"NMI: {louvain_metrics['nmi']:.4f}\")\n",
    "print(f\"ARI: {louvain_metrics['ari']:.4f}\")\n",
    "print(f\"Modularity: {louvain_metrics['modularity']:.4f}\")\n",
    "\n",
    "# Save results\n",
    "os.makedirs('results', exist_ok=True)\n",
    "louvain_result = {\n",
    "    'communities': louvain_communities,\n",
    "    'execution_time': louvain_time,\n",
    "    'metrics': louvain_metrics,\n",
    "    'num_communities': len(set(louvain_communities.values()))\n",
    "}\n",
    "with open('results/louvain_result.pkl', 'wb') as f:\n",
    "    pickle.dump(louvain_result, f)\n",
    "\n",
    "# Visualize detected communities\n",
    "plot_communities(G, louvain_communities, title=f\"Louvain Method - {len(set(louvain_communities.values()))} communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Label Propagation algorithm\n",
    "print(\"Running Label Propagation method...\")\n",
    "lp_communities, lp_time = run_label_propagation(G)\n",
    "\n",
    "# Add detected communities to the graph\n",
    "G = add_communities_to_graph(G, lp_communities, attr_name='lp_community')\n",
    "\n",
    "# Evaluate against ground truth\n",
    "lp_metrics = evaluate_against_ground_truth(G, lp_communities, 'community')\n",
    "print(f\"Execution time: {lp_time:.4f} seconds\")\n",
    "print(f\"Number of communities detected: {len(set(lp_communities.values()))}\")\n",
    "print(f\"NMI: {lp_metrics['nmi']:.4f}\")\n",
    "print(f\"ARI: {lp_metrics['ari']:.4f}\")\n",
    "print(f\"Modularity: {lp_metrics['modularity']:.4f}\")\n",
    "\n",
    "# Save results\n",
    "lp_result = {\n",
    "    'communities': lp_communities,\n",
    "    'execution_time': lp_time,\n",
    "    'metrics': lp_metrics,\n",
    "    'num_communities': len(set(lp_communities.values()))\n",
    "}\n",
    "with open('results/label_propagation_result.pkl', 'wb') as f:\n",
    "    pickle.dump(lp_result, f)\n",
    "\n",
    "# Visualize detected communities\n",
    "plot_communities(G, lp_communities, title=f\"Label Propagation - {len(set(lp_communities.values()))} communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of ground truth communities\n",
    "n_communities = len(set(ground_truth.values()))\n",
    "\n",
    "# Run Spectral Clustering algorithm\n",
    "print(f\"Running Spectral Clustering with {n_communities} clusters...\")\n",
    "spectral_communities, spectral_time = run_spectral_clustering(G, n_communities)\n",
    "\n",
    "# Add detected communities to the graph\n",
    "G = add_communities_to_graph(G, spectral_communities, attr_name='spectral_community')\n",
    "\n",
    "# Evaluate against ground truth\n",
    "spectral_metrics = evaluate_against_ground_truth(G, spectral_communities, 'community')\n",
    "print(f\"Execution time: {spectral_time:.4f} seconds\")\n",
    "print(f\"Number of communities detected: {len(set(spectral_communities.values()))}\")\n",
    "print(f\"NMI: {spectral_metrics['nmi']:.4f}\")\n",
    "print(f\"ARI: {spectral_metrics['ari']:.4f}\")\n",
    "print(f\"Modularity: {spectral_metrics['modularity']:.4f}\")\n",
    "\n",
    "# Save results\n",
    "spectral_result = {\n",
    "    'communities': spectral_communities,\n",
    "    'execution_time': spectral_time,\n",
    "    'metrics': spectral_metrics,\n",
    "    'num_communities': len(set(spectral_communities.values()))\n",
    "}\n",
    "with open('results/spectral_clustering_result.pkl', 'wb') as f:\n",
    "    pickle.dump(spectral_result, f)\n",
    "\n",
    "# Visualize detected communities\n",
    "plot_communities(G, spectral_communities, \n",
    "               title=f\"Spectral Clustering - {len(set(spectral_communities.values()))} communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Infomap (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cdlib is available for Infomap\n",
    "try:\n",
    "    from cdlib import algorithms\n",
    "    CDLIB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CDLIB_AVAILABLE = False\n",
    "    print(\"cdlib not available. Skipping Infomap.\")\n",
    "\n",
    "if CDLIB_AVAILABLE:\n",
    "    # Run Infomap algorithm\n",
    "    print(\"Running Infomap method...\")\n",
    "    infomap_communities, infomap_time = run_infomap(G)\n",
    "    \n",
    "    # Add detected communities to the graph\n",
    "    G = add_communities_to_graph(G, infomap_communities, attr_name='infomap_community')\n",
    "    \n",
    "    # Evaluate against ground truth\n",
    "    infomap_metrics = evaluate_against_ground_truth(G, infomap_communities, 'community')\n",
    "    print(f\"Execution time: {infomap_time:.4f} seconds\")\n",
    "    print(f\"Number of communities detected: {len(set(infomap_communities.values()))}\")\n",
    "    print(f\"NMI: {infomap_metrics['nmi']:.4f}\")\n",
    "    print(f\"ARI: {infomap_metrics['ari']:.4f}\")\n",
    "    print(f\"Modularity: {infomap_metrics['modularity']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    infomap_result = {\n",
    "        'communities': infomap_communities,\n",
    "        'execution_time': infomap_time,\n",
    "        'metrics': infomap_metrics,\n",
    "        'num_communities': len(set(infomap_communities.values()))\n",
    "    }\n",
    "    with open('results/infomap_result.pkl', 'wb') as f:\n",
    "        pickle.dump(infomap_result, f)\n",
    "    \n",
    "    # Visualize detected communities\n",
    "    plot_communities(G, infomap_communities, \n",
    "                  title=f\"Infomap - {len(set(infomap_communities.values()))} communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Leiden (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cdlib is available for Leiden\n",
    "if CDLIB_AVAILABLE:\n",
    "    # Run Leiden algorithm\n",
    "    print(\"Running Leiden method...\")\n",
    "    leiden_communities, leiden_time = run_leiden(G)\n",
    "    \n",
    "    # Add detected communities to the graph\n",
    "    G = add_communities_to_graph(G, leiden_communities, attr_name='leiden_community')\n",
    "    \n",
    "    # Evaluate against ground truth\n",
    "    leiden_metrics = evaluate_against_ground_truth(G, leiden_communities, 'community')\n",
    "    print(f\"Execution time: {leiden_time:.4f} seconds\")\n",
    "    print(f\"Number of communities detected: {len(set(leiden_communities.values()))}\")\n",
    "    print(f\"NMI: {leiden_metrics['nmi']:.4f}\")\n",
    "    print(f\"ARI: {leiden_metrics['ari']:.4f}\")\n",
    "    print(f\"Modularity: {leiden_metrics['modularity']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    leiden_result = {\n",
    "        'communities': leiden_communities,\n",
    "        'execution_time': leiden_time,\n",
    "        'metrics': leiden_metrics,\n",
    "        'num_communities': len(set(leiden_communities.values()))\n",
    "    }\n",
    "    with open('results/leiden_result.pkl', 'wb') as f:\n",
    "        pickle.dump(leiden_result, f)\n",
    "    \n",
    "    # Visualize detected communities\n",
    "    plot_communities(G, leiden_communities, \n",
    "                  title=f\"Leiden - {len(set(leiden_communities.values()))} communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare All Methods\n",
    "\n",
    "Now let's run a comparison of all the traditional methods to see how they perform against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of ground truth communities for spectral clustering\n",
    "n_clusters = len(set(ground_truth.values()))\n",
    "\n",
    "# Run comparison of methods\n",
    "print(\"Comparing different community detection methods...\")\n",
    "results_df = compare_methods(G, ground_truth_attr='community', n_clusters=n_clusters)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nComparison Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the comparison results\n",
    "results_df.write_parquet('results/traditional_methods_comparison.parquet', compression=\"zstd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Comparison Results\n",
    "\n",
    "Let's create some visualizations to better understand the comparison results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert polars DataFrame to pandas for visualization\n",
    "results_pd = results_df.to_pandas()\n",
    "\n",
    "# Visualize NMI and ARI\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot NMI and ARI\n",
    "plt.subplot(1, 2, 1)\n",
    "results_pd.plot(x='Method', y=['NMI', 'ARI'], kind='bar', ax=plt.gca())\n",
    "plt.title('Quality Metrics by Method')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Plot execution time\n",
    "plt.subplot(1, 2, 2)\n",
    "results_pd.plot(x='Method', y='Execution Time (s)', kind='bar', ax=plt.gca(), color='green')\n",
    "plt.title('Execution Time by Method')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of NMI vs. Execution Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(results_pd['Execution Time (s)'], results_pd['NMI'], \n",
    "           s=results_pd['Num Communities']*20, alpha=0.7)\n",
    "\n",
    "# Add method names as annotations\n",
    "for _, row in results_pd.iterrows():\n",
    "    plt.annotate(row['Method'], \n",
    "                (row['Execution Time (s)'], row['NMI']),\n",
    "                textcoords=\"offset points\", \n",
    "                xytext=(0,10), \n",
    "                ha='center')\n",
    "\n",
    "plt.title('NMI vs. Execution Time')\n",
    "plt.xlabel('Execution Time (seconds)')\n",
    "plt.ylabel('NMI')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Conclusions\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Applied various traditional community detection methods to our test graph\n",
    "   - Louvain\n",
    "   - Label Propagation\n",
    "   - Spectral Clustering\n",
    "   - Infomap (if available)\n",
    "   - Leiden (if available)\n",
    "2. Evaluated each method using NMI, ARI, and modularity\n",
    "3. Compared the methods in terms of quality and performance\n",
    "4. Visualized the detected communities and comparison results\n",
    "\n",
    "Based on the results, we can see which methods perform best for our test graph in terms of both accuracy and computational efficiency. This information will be valuable for comparing with the GNN-based approaches in the next notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}